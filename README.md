# AMC: Attention guided Multi-modal Correlation Learning for Image Search
This repository includes annotated keyword datasets used by AMC system (CVPR 2017)

## Introduction

**AMC System** is initially described in an [arxiv tech report](https://arxiv.org/abs/1704.00763). We leverage visual and textual modalities for image search by learning their correlation with input query. According to the intent of query, attention mechanism can be introduced to adaptively balance the importance of different modalities.

## Framework

The framework of AMC is shown below

<img src='img/pipeline_new.png' width='800'>

We propose a novel Attention guided Multi-modal Correlation (AMC) learning method which consists of a jointly learned hierarchy of intra and inter-attention networks. Conditioned on query's intent, intra-attention networks (i.e., visual intra-attention network and language intra-attention network) attend on informative parts within each modality; a multi-modal inter-attention network promotes the importance of the most query-relevant modalities.




## Keyword Dataset
To be released soon
